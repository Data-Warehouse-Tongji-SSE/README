# 数据仓库课程项目报告

## 重要说明

我们使用了 `BigDataWareHouse` 的 `deploy` 分支来配置三个数据库（`MySQL`, `Hive`, `Neo4j`）的环境，然后手动导入数据。

**注意：**

 - `docker-compose down` 再 `docker-compose up` 会使导入的数据丢失。
 - 在阿里云上把 `Hive` 高负载运行到半夜 12 点（恰好这个时间点）可能会损坏系统内核，原因不明。

如果使用 `BigDataWareHouse` 上游仓库的最新分支，也许可以自动导入数据并附带后端。只需要处理数据并完成前端即可。

## 每种存储方式适用查询

### MySQL

#### 优点

 - 服务较为稳定，很少出现异常宕机。
 - 结构化的存储方式较为严谨，通过建立表结构能有效规范和划分数据存储的类别，一目了然，如果遇到一份相对较完整，内部联系较少的数据，MySQL具有较高的存储性能和查询性能。另外，支持建立索引用于提高查询性能。

#### 缺点

 - 结构化的存储方式，使得数据库表之间的联系不易于表达，只能通过外键和主键等关系表示，如果关系错综复杂，在查询性能上会大打折扣。
 - 特别是一个表中数据量较大时，联表查询查询记录条数将会呈指数级增长。
 - 在本项目中，在执行单表查询时性能较为良好，但在执行连表查询时性能会急剧下降。

#### 适用场景

 - MySQL适用于在数据库表设计时，各表之间较为独立，内聚性较强，耦合性较弱，且联表查询次数较少的场景。

### Hive

#### 优点

 - 操作接口采用类SQL语法，学习成本低。
 - Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数，具有一定的延展性。
 - 当数据量较大时，Hive的并行运算优势就会体现出来。


#### 缺点

 - Hive基于MapReduce框架进行运行，本身具有高延迟性。在数据量较小时，数据查询的高延迟性非常明显。
 - 拖累Hive运行速度的关键是子查询，当子查询中使用了join、count(distinct)+group by时会进一步减慢运行速度，增加数据倾斜。
 - hive只支持查询和插入,插入是追加写,不是随机写。hive不支持随机写,相当于无法随机的更新某一行的内容,也无法随机的删除某一行的内容,因为更新和删除都属于随机写。
 - Hive的执行延迟比较高，因此Hive常用于数据分析，对实时性要求不高的场合。
 - 本项目中进行根据导演、演员、电影类别查询电影信息时，由于需要进行join操作，导致查询速度很慢。


#### 适用场景

 - 数据量足够大；不需要随机更新或删除某一行数据；不需要进行join、count(distinct)+group by等复杂的子查询；非实时查询。


### Neo4j

#### 优点

 - 相较于普通的表结构数据库，图数据库采用图的数据结构存储数据。Neo4j图数据库明显的优点是，存储数据不需要像普通数据库一样建立一张张数据表，在图数据结构中只有节点和边两种数据。这种非结构化的存储方式，在数据库设计方面有很大的灵活性，也能很好的适应需求变化，支持更多的算法设计。
 - 无论是插入新数据或者查询数据信息，一律只需要考虑节点属性和边属性。得益于Neo4j特殊的图数据结构和存储算法，Neo4j的节点的类别、属性，边的类别和属性都是分开存储的，节点中保留与之有联系的边和节点的对应信息，在查询性能上有了更大的优化，查询时间也会大大降低。
 - 另外，图数据结构特殊的边与表结构数据库中表之间的关系相比，不仅在界面上更加可视化，而且存储更加方便，查询速度更快，当在数据库中需要建立多个数据之间的相互联系时，Neo4j数据库的优势就显而易见了。
 - 在本项目中，当对某个节点的属性进行条件过滤并返回节点时，Neo4j在这方面有着极高的查询性能，Neo4j能够及其精准的找到符合条件的节点并返回，得益于特殊的图节点的存储数据结构。另外在对图关系查询时，关系中存储了两端节点的指针，在查询方面也有较大程度的优化。

#### 缺点

 - 在Neo4j数据库中，节点中会存储部分边的信息，边中也会存储部分节点的信息，因此，当一个节点上的边较多，这个节点上就会存储许多与其相关的边的信息，从而导致部分存储信息的冗余，影响存储性能，有关该节点的操作速度会下降许多。

#### 适用场景

 - 当设计模型为敏捷开发或增量模型时，为了应对逐步发展的需求的变化，需要灵活性较强的数据库设计方案和结构支持，Neo4j就是一个不错的选择。另外，当数据中有着错综复杂的关系时，使用结构化的存储方式会给编码人员带来极大的困难，neo4j数据库也适用于此场景。Neo4j适合存储修改较少，查询较多，没有超大节点的图数据。

## 存储优化

将经常一起使用的信息存储在同一张表里，提高内聚性，降低耦合性，减少联表查询的次数，提高查询性能。

由于查询导演和演员合作次数比较复杂，我们是以电影为查询主要内容，因此只构建了电影与导演、电影与演员之间的关系，导致查询导演和演员之间的合作次数时需要先查询电影，耗时较大，因此我们将导演和演员的合作次数做了事先处理，计算出每一组导演和演员的合作次数，并新建一张表（在Neo4j中用边来表示）用来存储他们的合作次数。

由于多表联合查询造成的时间开销过于庞大，优化使用了分段查询的办法，分别在行数较少的表中查询出电影的ID，再通过后端处理找到不同表查询结果的交集后再用这个ID去长行数的表中查询得到最终结果。

## 数据质量

### 如何保证数据质量？

我们的数据来源自Snap的文本文件和Amazon网站，Amazon作为权威的网站，数据源的数据准确性有所保证。

当爬取网页获取数据时，我们会解析网页，并将需要用于支持电影信息查询的信息精确爬下来，在爬取信息的过程中，会遇到部分网页信息存储结构与普通网页不同的情况，我们会将这些商品ID存入错误信息的文件中，而不是将它们忽略，从而保证了数据的完整性和准确性。

在获取到数据之后，我们按照一定的标准对关键字段进行统一命名、格式、精度等，排除数据的歧义，降低数据查询和统计的误差。同时，我们对获取的数据进行预处理，例如从253059个商品中筛选出其中的电影、对同一部电影的不同版本进行合并、去除掉导演、主演、参演名字中多余的空格，并将网页中同一数据字段的不同格式统一为一种格式，为之后的数据库存储做好充足的准备。

如果在存入数据仓库之后，发现数据质量出现问题时，我们对出现质量问题的数据的源数据进行处理，并将数据仓库里的问题数据替换成新处理的数据，保证数据的准确性和最新性。

### 哪些情况会影响数据质量？

从Amazon网站中利用爬虫获取253,059个Product页面，通过商品ID爬取网页时，有时候会出现404 not found，意味着该商品ID对应的网页不存在，如果不做充足的特殊处理，数据质量会受到影响。

Amazon网站具有一些反扒机制，数据爬取有时会失败。

爬取数据的过程中收集到的数据经常会带有特殊字符，用UTF-8格式进行编码和解码会出现乱码。

数据没有按一定的标准对关键字段进行统一命名、格式、精度等，有可能会出现多个相同的人名由于多了首尾空格导致被识别为两个不同的字符串。

数据预处理时没有对数据类型进行判断，从而错误处理部分数据。

## 数据血缘

### ETL与数据预处理

ETL与数据预处理阶段的工作目的是为了在网页源代码中筛选存储需要的字段信息，同时保证数据的完整性和准确性。

首先我们从评论文件中筛选出253059各商品ID，作为我们爬取亚马逊商品网页的基本准备，然后根据ID将亚马逊商品网页的源代码爬取下来并存储在文件中，然后再解析网页源代码并从中获取需要的字段和信息，因此我们基础的商品信息，包括商品ID，标题，时长，导演，演员等信息等数据来源为亚马逊网页源代码。

然后我们去除不存在商品和非电影后，使用并查集将同一电影的不同版本合并后，由于亚马逊的机制是同一电影的不同网页的具体细节和信息都是相同的，因此这里每一部电影采用一条记录进行存储，再加入一个新字段用于记录该电影有多少个不同的版本，基础的商品信息经过处理获得合并相同电影的新信息。

接着遍历评论文件中的所有文件，找到包含于现有电影ID中的电影评论，并将其分离出来，然后将其电影信息与对应评论信息进行合并，再将一些容易引歧义或格式不统一的字段信息统一处理，产生最终数据的数据血缘。

### MySQL

根据ETL处理后的数据，将其划分为11张表，分别为电影movie、类别genres、类别与导演关系表genres_relation、导演关系director_relation、主演starring_relation、参演actor_relation、评论comment、导演演员合作cooperation_relation、用户表use_id、person表和产品表product_id。其中comment表中的内容与user和product联系，person表和movie表通过一系列关系表关联，详情可见数据库ER图。

### Hive

根据ETL处理后的数据，将其划分为8张表，分别为电影movie、类别genres、导演director、演员starring、参演actor、评论comment、导演演员合作dir_act_relation和演员合作act_act_relation。其中类别genres、导演directorr、演员starring、参演actor、评论comment的属性id都是来源于电影movie的id。

再执行查询的过程中，我们发现到如果需要查询导演和演员的合作关系时，需要先将演员starring和参演actor表进行union拼接，再和导演director进行join拼接，再通过count+group by进行次数计算，最后再通过order by进行排序。这样太耗费时间。为了提高查询性能，我们又在从源数据中处理获得导演和演员的合作关系，并将其导入Hive数据仓库，形成合作关系，提高查询性能，增强数据质量。

### Neo4j

根据ETL处理后的数据，将其划分为4种节点，分别为类别，电影，人物和用户，并赋予节点对应的属性边划分为6种边，分别为评论关系、执导关系、主演关系、参演关系、类别关系和合作关系，其中前五项是第一步导入的边，这其中产生了数据链路关系。

再执行查询的过程中，我们发现到如果需要查询导演和演员的合作关系时，需要先查询电影作为两者的中间节点，进行了许多不必要的计算，为了提高查询性能，我们又在从源数据中处理获得导演和演员的合作关系，并将其导入Neo4j数据库，形成合作关系，提高查询性能，增强数据质量。
